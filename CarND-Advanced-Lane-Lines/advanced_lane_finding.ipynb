{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Load camera calibration\n",
    "with open('camera_cal.p', mode='rb') as f:\n",
    "    camera_cal=pickle.load(f)\n",
    "mtx=camera_cal['mtx']\n",
    "dist=camera_cal['dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "\n",
    "left_line=Line()\n",
    "right_line=Line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "# Colour transform\n",
    "def color_thresh(img, thresh=(0,255)):\n",
    "    hls=cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s=hls[:,:,2]\n",
    "\n",
    "    # Color threshold to isolate yellow and white \n",
    "    s_binary=np.zeros_like(s)\n",
    "    s_binary[[((s>=thresh[0]) & (s<=thresh[1]))]]=1\n",
    "    \n",
    "    #plt.imshow(np.dstack((255*s_binary,np.zeros_like(s), s)))\n",
    "    #plt.show()\n",
    "    return (s_binary)\n",
    "\n",
    "def r_color_thresh(img, thresh=(0,255)):\n",
    "    r=img[:,:,0]\n",
    "\n",
    "    # Color threshold to isolate yellow and white \n",
    "    r_binary=np.zeros_like(r)\n",
    "    r_binary[[((r>=thresh[0]) & (r<=thresh[1]))]]=1\n",
    "    \n",
    "    #plt.imshow(np.dstack((255*s_binary,np.zeros_like(s), s)))\n",
    "    #plt.show()\n",
    "    return (r_binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(gray, orient='x', sobel_kernel=3, thresh=(0,255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    #default is to use sobel x\n",
    "    if orient=='x':\n",
    "        gradient=cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    if orient=='y':\n",
    "        gradient=cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=sobel_kernel)        \n",
    "\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_grad=np.absolute(gradient)\n",
    "\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scale_factor=np.max(abs_grad)/255.0\n",
    "    abs_grad=(abs_grad/scale_factor).astype(np.uint8)\n",
    "\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    mask=[(abs_grad>thresh[0]) & (abs_grad<thresh[1])]\n",
    "\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    binary_output=np.zeros_like(abs_grad).astype(np.uint8)\n",
    "    binary_output[mask]=1    \n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(gray, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "   \n",
    "    # Apply the following steps to img\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx=cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely=cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Calculate the magnitude\n",
    "    sobel_mag=np.sqrt(sobelx**2+sobely**2)\n",
    "    # 5) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        sobel_mag=np.uint8(255*sobel_mag/np.max(sobel_mag))\n",
    "    # 6) Create a binary mask where mag thresholds are met\n",
    "    mask =[(sobel_mag > mag_thresh[0]) & (sobel_mag < mag_thresh[1])]\n",
    "    # 7) Return this mask as your binary_output image\n",
    "    binary_output=np.zeros_like(sobel_mag).astype(np.uint8)\n",
    "    binary_output[mask] = 1\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(gray, sobel_kernel=3, thresh=(0, np.pi/2)):    \n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx=cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely=cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Calculate the direction of the gradient \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        sobel_phase=np.arctan(sobely/(sobelx))\n",
    "        # 4) Take the absolute value\n",
    "        sobel_abs_phase=np.absolute(sobel_phase)\n",
    "        # 5) Create a binary mask where direction thresholds are met\n",
    "        mask =[(sobel_abs_phase > thresh[0]) & (sobel_abs_phase < thresh[1])]\n",
    "        # 6) Return this mask as your binary_output image\n",
    "        dir_binary=np.zeros_like(sobel_abs_phase).astype(np.uint8)\n",
    "        dir_binary[mask] = 1\n",
    "    return dir_binary\n",
    "\n",
    "def detect_sobel_edges(gray):\n",
    "    ksize=13\n",
    "    gradx = abs_sobel_thresh(gray, orient='x', sobel_kernel=ksize, thresh=(1, 255))\n",
    "    grady = abs_sobel_thresh(gray, orient='y', sobel_kernel=ksize, thresh=(10, 255))\n",
    "    mag_binary = mag_thresh(gray, sobel_kernel=ksize, mag_thresh=(50, 255))\n",
    "    dir_binary = dir_threshold(gray, sobel_kernel=ksize, thresh=(2*np.pi/18, 6*np.pi/18))\n",
    "    \n",
    "    edges = np.zeros_like(dir_binary)\n",
    "    #edges[((gradx == 1) & (grady == 1)) & ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    edges[((gradx == 1) & (dir_binary == 1) & (mag_binary == 1))] = 1\n",
    "    #edges[((gradx == 1) )] = 1\n",
    "\n",
    "    return edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Region masking\n",
    "def region_masking(img):\n",
    "    ysize = img.shape[0]\n",
    "    xsize = img.shape[1]\n",
    "\n",
    "    left_bottom = [0.0*xsize, ysize-1]\n",
    "    left_top = [0.45*xsize, 0.6*ysize]\n",
    "    right_top = [0.55*xsize, 0.6*ysize]\n",
    "    right_bottom = [1*xsize, ysize-1]\n",
    "\n",
    "    # Fit lines (y=Ax+B) to identify the  3 sided region of interest\n",
    "    # np.polyfit() returns the coefficients [A, B] of the fit\n",
    "    fit_left = np.polyfit((left_bottom[0], left_top[0]), (left_bottom[1], left_top[1]), 1)\n",
    "    fit_top = np.polyfit((left_top[0], right_top[0]), (left_top[1], right_top[1]), 1)\n",
    "    fit_right = np.polyfit((right_top[0], right_bottom[0]), (right_top[1], right_bottom[1]), 1)\n",
    "    fit_bottom = np.polyfit((left_bottom[0], right_bottom[0]), (left_bottom[1], right_bottom[1]), 1)\n",
    "\n",
    "    # Find the region inside the lines\n",
    "    XX, YY = np.meshgrid(np.arange(0, xsize), np.arange(0, ysize))\n",
    "    region_thresholds = (YY > (XX*fit_left[0] + fit_left[1])) & \\\n",
    "                        (YY > (XX*fit_top[0] + fit_top[1])) & \\\n",
    "                        (YY > (XX*fit_right[0] + fit_right[1])) & \\\n",
    "                        (YY < (XX*fit_bottom[0] + fit_bottom[1]))\n",
    "\n",
    "    binary_lane=np.zeros_like(img)\n",
    "    binary_lane[region_thresholds & (img==1)]=1\n",
    "        \n",
    "    return binary_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_slope(line):\n",
    "    [[x1,y1,x2,y2]]=line\n",
    "    slope=(y2-y1)/(x2-x1)\n",
    "    return slope\n",
    "\n",
    "def find_lane_trapezoid(img, lines, color=[255, 0, 0], thickness=7):   \n",
    "    shape_ymax, shape_xmax = img.shape\n",
    "   \n",
    "    \"\"\"   Calculate slopes and group the lines into left and right     \"\"\"\n",
    "    right_lines=[]\n",
    "    left_lines=[]\n",
    "    slopes=[]\n",
    "    slope_thres=0.5\n",
    "    for line in lines:\n",
    "        slope=calc_slope(line)\n",
    "        slopes.append(slope)\n",
    "        if(slope>slope_thres):\n",
    "            right_lines.append(line)\n",
    "        elif(slope<-slope_thres):\n",
    "            left_lines.append(line)\n",
    "\n",
    "    \"\"\"        Averaging        \"\"\"\n",
    "    left_line =np.mean(left_lines,axis=0)\n",
    "    left_line =left_line.astype(int)\n",
    "    right_line=np.mean(right_lines,axis=0)\n",
    "    right_line=right_line.astype(int)\n",
    "\n",
    "    \"\"\"        Extrapolate        \"\"\"\n",
    "    y_thres=int(0.8*shape_ymax)\n",
    "    m=calc_slope(left_line)\n",
    "    [[x1,y1,x2,y2]]=left_line\n",
    "    xmin_left=int(x1+(shape_ymax-y1)/m)\n",
    "    xmax_left=int(x2-(y2-y_thres)/m)\n",
    "    #cv2.line(img, (xmin_left, shape_ymax), (xmax_left, y_thres), color, thickness)\n",
    "\n",
    "    m=calc_slope(right_line)\n",
    "    [[x1,y1,x2,y2]]=right_line\n",
    "    xmax_right=int(x2+(shape_ymax-y2)/m)\n",
    "    xmin_right=int(x1-(y1-y_thres)/m)        \n",
    "    #cv2.line(img, (xmin_right, y_thres), (xmax_right, shape_ymax), color, thickness)    \n",
    "    #cv2.line(img, (xmax_left, y_thres), (xmin_right, y_thres), color, thickness)\n",
    "    \n",
    "    trapezoid_corners=[[xmin_left, shape_ymax],[xmax_left, y_thres],[xmin_right, y_thres],[xmax_right, shape_ymax]]    \n",
    "    #plt.imshow(img, cmap='gray')\n",
    "    #plt.show()\n",
    "    return trapezoid_corners\n",
    "    \n",
    "def hough_lines(hough_img, rho=2, theta= np.pi/180, threshold=40, min_line_len=10, max_line_gap=170):\n",
    "    \"\"\"   Take only the bottom part of the image which is more likely to be straight lines     \"\"\"\n",
    "    \"\"\"   This is to avoid the upper curve line to skew the straight line finding  \"\"\"\n",
    "    shape_ymax, shape_xmax = hough_img.shape\n",
    "    img=hough_img.copy()\n",
    "    img[:int(0.7*shape_ymax),:]=0    \n",
    "    #plt.imshow(img,cmap='gray')\n",
    "    #plt.show()\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold,np.array([]),min_line_len, max_line_gap)\n",
    "    return lines\n",
    "\n",
    "# Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "def find_trapezoid_corners(img):\n",
    "    # Hough transform to find line\n",
    "    #line_image = np.copy(binary_lane,np.uint8)\n",
    "    # Run Hough on edge detected image\n",
    "    lines = hough_lines(img.copy())\n",
    "    # Find straight 4 trapezoid corners on the straight lanes\n",
    "    scr_pts=find_lane_trapezoid(img.copy(),lines)\n",
    "    \n",
    "    return scr_pts\n",
    "\n",
    "def bird_eye(img, src_pts, dst_pts):\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src_pts,dst_pts)\n",
    "    \n",
    "    warped=cv2.warpPerspective(img,M,img.shape[::-1],flags=cv2.INTER_LINEAR)\n",
    "    return warped, M\n",
    "\n",
    "# Find lane boundary\n",
    "# Function to find lane boundary and return an binary image\n",
    "def find_lane(img, x_init_pos, wdw_dx=75, wdw_dy=4*36):\n",
    "    shape_ymax, shape_xmax=img.shape\n",
    "    windowed=np.zeros_like(img)\n",
    "    # start the search from peak\n",
    "    x_mean=x_init_pos\n",
    "    for y in range(shape_ymax, 0, -wdw_dy):\n",
    "        wdw=img[y-wdw_dy:y,x_mean-wdw_dx:x_mean+wdw_dx].copy()\n",
    "        windowed[y-wdw_dy:y,x_mean-wdw_dx:x_mean+wdw_dx]=wdw.copy()\n",
    "        # Calculate new mean of x\n",
    "        histogram = np.sum(wdw, axis=0)\n",
    "        if (np.sum(histogram)!=0): # found pixels, update the mean location        \n",
    "            x_mean=x_mean-wdw_dx+np.argmax(histogram)\n",
    "\n",
    "        #print(histogram)\n",
    "        #print(x_init_pos, np.argmax(histogram), x_mean)\n",
    "    return windowed\n",
    "\n",
    "# Detect lane pixels and fit to find lane boundary\n",
    "def find_lane_boundary(img, left_start, right_start, dbg=False):\n",
    "    # mask the bottom centre area\n",
    "    shape_ymax, shape_xmax=img.shape    \n",
    "    x_center=int(shape_xmax/2)\n",
    "    img[shape_ymax-100:shape_ymax,x_center-150:x_center+150]=0        \n",
    "    \n",
    "    left_lane=find_lane(img, left_start)\n",
    "    right_lane=find_lane(img, right_start)\n",
    "    \n",
    "    return left_lane, right_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine curvature of the lane and vehicle position with respect to center\n",
    "def fit_polynomial(lane_img, line, dbg=False):\n",
    "    \n",
    "    shape_ymax, shape_xmax = lane_img.shape\n",
    "    y = np.linspace(0, shape_ymax, num=shape_ymax)\n",
    "\n",
    "    # Get the x,y indexes with non-zero elements i.e. white lines\n",
    "    y_pts,x_pts=np.nonzero(lane_img)\n",
    "\n",
    "    # Polynomial fitting\n",
    "    line.fit=np.polyfit(y_pts,x_pts,2)\n",
    "    line.recent_xfitted = line.fit[0]*y**2 + line.fit[1]*y + line.fit[2]\n",
    "    \n",
    "    y_bottom=shape_ymax-1\n",
    "    line.line_base_pos = line.fit[0]*y_bottom**2 + line.fit[1]*y_bottom + line.fit[2]\n",
    "    if dbg==True:\n",
    "        # Plt on graph\n",
    "        plt.plot(x_pts, y_pts, '.', color='white')\n",
    "        plt.plot(line.recent_xfitted, y, color='red', linewidth=3)\n",
    "\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(0, 720)\n",
    "        ax = plt.gca()\n",
    "        ax.set_axis_bgcolor('black')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.show()\n",
    "\n",
    "def calc_curvature(lane_img, line, xm_per_pix, ym_per_pix):\n",
    "    # Curvature\n",
    "    shape_ymax, shape_xmax = lane_img.shape\n",
    "    y_pts,x_pts=np.nonzero(lane_img)\n",
    "    y_eval = shape_ymax\n",
    "    fit_cr=np.polyfit(y_pts*ym_per_pix,x_pts*xm_per_pix,2)\n",
    "\n",
    "    line.radius_of_curvature = ((1 + (2*fit_cr[0]*y_eval + fit_cr[1])**2)**1.5) \\\n",
    "                                 /np.absolute(2*fit_cr[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fill_poly_unwarp(img, warped, warp_matrix, left_fit, right_fit):\n",
    "    # Warp the detected lane boundaries back onto the original image\n",
    "    shape_ymax, shape_xmax, _ =img.shape\n",
    "    y = np.linspace(0, shape_ymax, num=shape_ymax)\n",
    "    left_fitted_curve = left_fit[0]*y**2 + left_fit[1]*y + left_fit[2]\n",
    "    right_fitted_curve = right_fit[0]*y**2 + right_fit[1]*y + right_fit[2]    \n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitted_curve, y]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitted_curve, y])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    Minv=np.linalg.inv(warp_matrix)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(img, left_line, right_line, color_filter='edge and color', dbg=False):\n",
    "    shape_ymax, shape_xmax, _ = img.shape\n",
    "    #Apply distortion correction to the raw image\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    if dbg==True:\n",
    "        plt.imshow(undist)\n",
    "        plt.show()\n",
    "\n",
    "    # Threshold color\n",
    "    color_binary=color_thresh(undist, (80,255))\n",
    "    #color_binary=r_color_thresh(undist, (200,255))\n",
    "    if dbg==True:\n",
    "        plt.imshow(color_binary, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "    # Threshold gradient\n",
    "    gray=cv2.cvtColor(undist, cv2.COLOR_RGB2GRAY)\n",
    "    edges=detect_sobel_edges(gray)\n",
    "    if dbg==True:\n",
    "        plt.imshow(edges, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    if dbg==True:\n",
    "        plt.imshow(255*np.dstack((color_binary,np.zeros_like(edges),edges)))\n",
    "        plt.show()\n",
    "\n",
    "    # Combine gradient and color thresholds\n",
    "    grad_color_masked=np.zeros_like(color_binary)\n",
    "    if color_filter=='edge and color':\n",
    "        grad_color_masked[(edges==1) | (color_binary==1)]=1        \n",
    "    else:\n",
    "        grad_color_masked[(edges==1)]=1 \n",
    "    \n",
    "    # remove horizontal shadow\n",
    "    #grad_color_masked=abs_sobel_thresh(grad_color_masked, orient='x', sobel_kernel=13, thresh=(40, 255))\n",
    "\n",
    "    if dbg==True:\n",
    "        plt.imshow(grad_color_masked, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    binary_lane=region_masking(grad_color_masked)\n",
    "    if dbg==True:\n",
    "        plt.imshow(binary_lane, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "    # Warp\n",
    "    \"\"\"\n",
    "    src_pts=find_trapezoid_corners(binary_lane)\n",
    "    temp_img=img.copy()\n",
    "    color=[255,0,0]\n",
    "    thickness=5\n",
    "    cv2.line(temp_img, (src_pts[0][0], src_pts[0][1]), (src_pts[1][0], src_pts[1][1]), color, thickness)    \n",
    "    cv2.line(temp_img, (src_pts[1][0], src_pts[1][1]), (src_pts[2][0], src_pts[2][1]), color, thickness)    \n",
    "    cv2.line(temp_img, (src_pts[2][0], src_pts[2][1]), (src_pts[3][0], src_pts[3][1]), color, thickness)        \n",
    "    plt.imshow(temp_img)\n",
    "    plt.show()\n",
    "    print(src_pts)\n",
    "    \"\"\"\n",
    "    src_pts=np.array([[271, shape_ymax], [453, 576], [925, 576], [1178, shape_ymax]],np.int)\n",
    "    dst_pts=np.array([[290, shape_ymax],[290, 0.85*shape_ymax],\n",
    "                  [990,0.85*shape_ymax],[990,shape_ymax]],np.int)\n",
    "    \n",
    "    warped, warp_matrix=bird_eye(binary_lane, np.float32(src_pts), np.float32(dst_pts))\n",
    "    if dbg==True:\n",
    "        plt.imshow(warped,cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    # Plot the trapezoid\n",
    "    \"\"\"\n",
    "    if dbg==True:    \n",
    "        line_pic = undist.copy()\n",
    "        color=[255,0,0]\n",
    "        thickness=10\n",
    "        cv2.line(line_pic, (src_pts[0][0], src_pts[0][1]), (src_pts[1][0], src_pts[1][1]),color, thickness)\n",
    "        cv2.line(line_pic, (src_pts[1][0], src_pts[1][1]), (src_pts[2][0], src_pts[2][1]),color, thickness)\n",
    "        cv2.line(line_pic, (src_pts[2][0], src_pts[2][1]), (src_pts[3][0], src_pts[3][1]),color, thickness)\n",
    "        cv2.line(line_pic, (src_pts[3][0], src_pts[3][1]), (src_pts[0][0], src_pts[0][1]),color, thickness)\n",
    "        plt.imshow(line_pic)\n",
    "        plt.show()\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define conversions in from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700\n",
    "    lane_width_m = 3.7\n",
    "    \n",
    "    # Find lanes\n",
    "    left_lane,right_lane=find_lane_boundary(warped, dst_pts[0][0],dst_pts[3][0],dbg)\n",
    "    if dbg==True:    \n",
    "        plt.imshow(left_lane,cmap='gray')\n",
    "        plt.show()\n",
    "        plt.imshow(right_lane,cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    combine_lanes=cv2.addWeighted(left_lane,1,right_lane,1,0)\n",
    "    if dbg==True:\n",
    "        plt.imshow(combine_lanes,cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "       \n",
    "    # Find curvature \n",
    "    #left_curverad,  right_curverad, left_fit, right_fit =  calc_curvature(left_lane, right_lane, xm_per_pix, ym_per_pix, dbg)\n",
    "    fit_polynomial(left_lane, left_line, dbg=dbg)\n",
    "    fit_polynomial(right_lane, right_line, dbg=dbg)\n",
    "        \n",
    "    calc_curvature(left_lane, left_line, xm_per_pix, ym_per_pix)\n",
    "    calc_curvature(right_lane, right_line, xm_per_pix, ym_per_pix)\n",
    "        \n",
    "    # Calculate the position of car relative to lane center\n",
    "    car_center=img.shape[1]/2\n",
    "    lane_center=(left_line.line_base_pos+right_line.line_base_pos)/2    \n",
    "    lane_offset=lane_width_m*(car_center-lane_center)/(right_line.line_base_pos-left_line.line_base_pos)\n",
    "    \n",
    "    if dbg==True:\n",
    "        print('lane_offset',lane_offset,'m')\n",
    "    \n",
    "\n",
    "    # iff both lanes curve to the same direction\n",
    "    #if np.sign(left_fit[0])==np.sign(left_fit[1]):\n",
    "        # update line parameters\n",
    "    left_line.best_fit=left_line.fit\n",
    "    right_line.best_fit=right_line.fit\n",
    "        \n",
    "    curverad=(left_line.radius_of_curvature+right_line.radius_of_curvature)/2\n",
    "    \n",
    "    # fill polygon and unwarp into original image\n",
    "    result=fill_poly_unwarp(undist, warped, warp_matrix, left_line.best_fit, right_line.best_fit)\n",
    "\n",
    "\n",
    "        \n",
    "    # add texts\n",
    "    cv2.putText(result, \"Radius of Curvature =\"+str(int(curverad))+\"(m)\", (20, 50),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2)\n",
    "    if lane_offset>0:\n",
    "        side=\"right\"\n",
    "    else:\n",
    "        side=\"left\"\n",
    "\n",
    "    cv2.putText(result, \"Vehicle is\"+\" %0.2fm \"%(np.abs(lane_offset))+side+\" of center\", (20, 100),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255,255,255), 2)\n",
    "    if dbg==True:    \n",
    "        plt.imshow(result)\n",
    "        plt.show()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"project_video.mp4\") #video_name is the video being called\n",
    "for fn in range(900,1250):\n",
    "    cap.set(1,fn); # Where frame_no is the frame you want\n",
    "    ret, frame = cap.read() # Read the frame\n",
    "    frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    ##\n",
    "    \"\"\"\n",
    "    ksize=13\n",
    "    gray=cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    gradx = abs_sobel_thresh(gray, orient='x', sobel_kernel=ksize, thresh=(1, 255))\n",
    "    grady = abs_sobel_thresh(gray, orient='y', sobel_kernel=ksize, thresh=(10, 255))\n",
    "    mag_binary = mag_thresh(gray, sobel_kernel=ksize, mag_thresh=(50, 255))\n",
    "    dir_binary = dir_threshold(gray, sobel_kernel=ksize, thresh=(2*np.pi/18, 6*np.pi/18))\n",
    "    \n",
    "    edges = np.zeros_like(dir_binary)\n",
    "    #edges[((gradx == 1) & (grady == 1)) & ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    edges[((gradx == 1) & (dir_binary == 1) & (mag_binary == 1))] = 1\n",
    "    #edges[((gradx == 1) )] = 1\n",
    "    #\n",
    "    plt.imshow(edges,cmap='gray')\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    \n",
    "    aug_frame=process_image(frame, left_line, right_line,dbg=False)\n",
    "    \n",
    "    aug_frame=cv2.cvtColor(aug_frame,cv2.COLOR_RGB2BGR)\n",
    "    cv2.putText(aug_frame, \"Frame \"+str(fn), (400, 450),\n",
    "           cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255), 2)    \n",
    "    \n",
    "    cv2.imshow('window_name', aug_frame) # show frame on window\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-7117a944b945>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m            cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255), 2)\n\u001b[1;32m      9\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frame'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maug_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m0xFF\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mvideo_in\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "video_in=cv2.VideoCapture(\"project_video.mp4\")\n",
    "fn=0\n",
    "while(True):\n",
    "    ret, frame=video_in.read()\n",
    "    fn+=1\n",
    "    aug_frame=process_image(frame)\n",
    "    cv2.putText(aug_frame, \"Frame \"+str(fn), (30, 100),\n",
    "           cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255), 2)\n",
    "    cv2.imshow('frame', aug_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_in.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_result.mp4\n",
      "[MoviePy] Writing video project_result.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████▉| 1260/1261 [09:33<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_result.mp4 \n",
      "\n",
      "Wall time: 9min 35s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"<moviepy.video.io.VideoFileClip.VideoFileClip object at 0x0000020655E889E8>\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def image_pipeline(img):\n",
    "    global left_line, right_line\n",
    "    return process_image(img, left_line, right_line)\n",
    "                  \n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "video_output = 'project_result.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "clip_output = clip1.fl_image(image_pipeline) #NOTE: this function expects color images!!\n",
    "%time clip_output.write_videofile(video_output, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(clip_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
